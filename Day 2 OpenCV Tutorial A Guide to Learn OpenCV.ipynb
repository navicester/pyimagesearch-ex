{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "thorough-shipping",
   "metadata": {},
   "source": [
    "## Day 2 OpenCV Tutorial A Guide to Learn OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "voluntary-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-development",
   "metadata": {},
   "source": [
    "### Loading and displaying an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bacterial-conspiracy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width=600, height=399, depth=3\n"
     ]
    }
   ],
   "source": [
    "# load the input image and show its dimensions, keeping in mind that\n",
    "# images are represented as a multi-dimensional NumPy array with\n",
    "# shape no. rows (height) x no. columns (width) x no. channels (depth)\n",
    "image = cv2.imread(\"images/jp.png\")\n",
    "(h, w, d) = image.shape\n",
    "print(\"width={}, height={}, depth={}\".format(w, h, d))\n",
    "\n",
    "# display the image to our screen -- we will need to click the window\n",
    "# open by OpenCV and press a key on our keyboard to continue execution\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-fitness",
   "metadata": {},
   "source": [
    "### Accessing individual pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "written-lighting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R=145, G=126, B=120\n"
     ]
    }
   ],
   "source": [
    "# access the RGB pixel located at x=50, y=100, keepind in mind that\n",
    "# OpenCV stores images in BGR order rather than RGB\n",
    "(B, G, R) = image[100, 50]\n",
    "print(\"R={}, G={}, B={}\".format(R, G, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-blogger",
   "metadata": {},
   "source": [
    "### Array slicing and cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recent-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a 100x100 pixel square ROI (Region of Interest) from the\n",
    "# input image starting at x=320,y=60 at ending at x=420,y=160\n",
    "roi = image[60:160, 320:420]\n",
    "cv2.imshow(\"ROI\", roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-loading",
   "metadata": {},
   "source": [
    "### Resizing images\n",
    "\n",
    "```cv2.resize```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "residential-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image to 200x200px, ignoring aspect ratio\n",
    "resized = cv2.resize(image, (200, 200))\n",
    "cv2.imshow(\"Fixed Resizing\", resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "english-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually computing the aspect ratio can be a pain so let's use the\n",
    "# imutils library instead\n",
    "resized = imutils.resize(image, width=300)\n",
    "cv2.imshow(\"Imutils Resize\", resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-marketing",
   "metadata": {},
   "source": [
    "### Rotating an image\n",
    "\n",
    "```cv2.getRotationMatrix2D```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "romance-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's rotate an image 45 degrees clockwise using OpenCV by first\n",
    "# computing the image center, then constructing the rotation matrix,\n",
    "# and then finally applying the affine warp\n",
    "center = (w // 2, h // 2)\n",
    "M = cv2.getRotationMatrix2D(center, -45, 1.0)\n",
    "rotated = cv2.warpAffine(image, M, (w, h))\n",
    "cv2.imshow(\"OpenCV Rotation\", rotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "incorporate-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotation can also be easily accomplished via imutils with less code\n",
    "rotated = imutils.rotate(image, -45)\n",
    "cv2.imshow(\"Imutils Rotation\", rotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "linear-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV doesn't \"care\" if our rotated image is clipped after rotation\n",
    "# so we can instead use another imutils convenience function to help\n",
    "# us out\n",
    "rotated = imutils.rotate_bound(image, 45)\n",
    "cv2.imshow(\"Imutils Bound Rotation\", rotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-spoke",
   "metadata": {},
   "source": [
    "### Smoothing an image\n",
    "\n",
    "```cv2.GaussianBlur```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exterior-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a Gaussian blur with a 11x11 kernel to the image to smooth it,\n",
    "# useful when reducing high frequency noise\n",
    "blurred = cv2.GaussianBlur(image, (11, 11), 0)\n",
    "cv2.imshow(\"Blurred\", blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-recording",
   "metadata": {},
   "source": [
    "### Drawing on an image\n",
    "\n",
    "```cv2.rectangle```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "quantitative-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a 2px thick red rectangle surrounding the face\n",
    "output = image.copy()\n",
    "cv2.rectangle(output, (320, 60), (420, 160), (0, 0, 255), 2)\n",
    "cv2.imshow(\"Rectangle\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c488a8d6",
   "metadata": {},
   "source": [
    "```cv2.circle```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cordless-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a blue 20px (filled in) circle on the image centered at\n",
    "# x=300,y=150\n",
    "output = image.copy()\n",
    "cv2.circle(output, (300, 150), 20, (255, 0, 0), -1)\n",
    "cv2.imshow(\"Circle\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7191a894",
   "metadata": {},
   "source": [
    "```cv2.line```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "broken-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a 5px thick red line from x=60,y=20 to x=400,y=200\n",
    "output = image.copy()\n",
    "cv2.line(output, (60, 20), (400, 200), (0, 0, 255), 5)\n",
    "cv2.imshow(\"Line\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c6f53e",
   "metadata": {},
   "source": [
    "```cv2.putText```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "negative-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw green text on the image\n",
    "output = image.copy()\n",
    "cv2.putText(output, \"OpenCV + Jurassic Park!!!\", (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Text\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-comparison",
   "metadata": {},
   "source": [
    "### Converting an image to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "homeless-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"images/tetris-blocks.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04056035",
   "metadata": {},
   "source": [
    "```cv2.cvtColor```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "synthetic-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray\", gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-heading",
   "metadata": {},
   "source": [
    "### Edge detection\n",
    "Edge detection is useful for finding boundaries of objects in an image â€” it is effective for segmentation purposes.\n",
    "\n",
    "```cv2.Canny```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pending-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying edge detection we can find the outlines of objects in images\n",
    "edged = cv2.Canny(gray, 30, 150)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-grade",
   "metadata": {},
   "source": [
    "### Thresholding\n",
    "Image thresholding is an important intermediary step for image processing pipelines. Thresholding can help us to remove lighter or darker regions and contours of images.\n",
    "\n",
    "```cv2.threshold```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "north-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold the image by setting all pixel values less than 225\n",
    "# to 255 (white; foreground) and all pixel values >= 225 to 255\n",
    "# (black; background), thereby segmenting the image\n",
    "thresh = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "cv2.imshow(\"Thresh\", thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-friend",
   "metadata": {},
   "source": [
    "### Detecting and drawing contours\n",
    "\n",
    "```cv2.findContours```\n",
    "\n",
    "```cv2.drawContours```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "critical-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours (i.e., outlines) of the foreground objects in the\n",
    "# thresholded image\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "output = image.copy()\n",
    "\n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "\t# draw each contour on the output image with a 3px thick purple\n",
    "\t# outline, then display the output contours one at a time\n",
    "\tcv2.drawContours(output, [c], -1, (240, 0, 159), 3)\n",
    "\tcv2.imshow(\"Contours\", output)\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fifth-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the total number of contours found in purple\n",
    "text = \"I found {} objects!\".format(len(cnts))\n",
    "cv2.putText(output, text, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (240, 0, 159), 2)\n",
    "cv2.imshow(\"Contours\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-president",
   "metadata": {},
   "source": [
    "### Erosions and dilations\n",
    "\n",
    "```cv2.erode```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rotary-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we apply erosions to reduce the size of foreground objects\n",
    "mask = thresh.copy()\n",
    "mask = cv2.erode(mask, None, iterations=5)\n",
    "cv2.imshow(\"Eroded\", mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "biological-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarly, dilations can increase the size of the ground objects\n",
    "mask = thresh.copy()\n",
    "mask = cv2.dilate(mask, None, iterations=5)\n",
    "cv2.imshow(\"Dilated\", mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-minority",
   "metadata": {},
   "source": [
    "### Masking and bitwise operations\n",
    "\n",
    "```cv2.bitwise_and```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bridal-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a typical operation we may want to apply is to take our mask and\n",
    "# apply a bitwise AND to our input image, keeping only the masked\n",
    "# regions\n",
    "mask = thresh.copy()\n",
    "output = cv2.bitwise_and(image, image, mask=mask)\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2691337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
